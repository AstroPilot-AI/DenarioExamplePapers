\documentclass[twocolumn]{aastex631}

\usepackage{amsmath}
\usepackage{multirow}
\usepackage{natbib}
\usepackage{graphicx} 
\usepackage{aas_macros}

\begin{document}

\subsection{Data Preprocessing}

The raw merger tree data, originating from cosmological N-body simulations, underwent a series of preprocessing steps to prepare it for use in the Graph Neural Network (GNN) model. The initial intention was to extract an assembly bias proxy from the structural properties of halo merger trees, as described in the introduction.

\subsubsection{Data Loading and Feature Extraction}
The merger tree dataset was loaded using the \texttt{torch.load(f\_tree, weights\_only=False)} function from the PyTorch library. This function deserializes a Python object saved from a PyTorch environment, in our case representing the merger trees. For each merger tree in the dataset, the following components were extracted: node features (\texttt{x}), edge indices (\texttt{edge\_index}), edge attributes (\texttt{edge\_attr}), target variable (\texttt{y}), and node halo IDs (\texttt{node\_halo\_id}). The node features (\texttt{x}) consist of halo mass, concentration, maximum circular velocity ($V_{max}$), and scale factor. The edge indices (\texttt{edge\_index}) define the connections between halos within the merger tree. The edge attributes (\texttt{edge\_attr}) include the merger mass ratio and the time difference between mergers. The target variable (\texttt{y}) represents the assembly bias proxy, and the node halo IDs (\texttt{node\_halo\_id}) are used to compute the assembly bias proxy.

\subsubsection{Log Transformation and Normalization}
To reduce skewness and improve the distribution of the data, a logarithmic transformation was applied to the halo mass and $V_{max}$ node features. Specifically, the original mass values (\texttt{x[:, 0]}) and $V_{max}$ values (\texttt{x[:, 2]}) were replaced with their base-10 logarithms using \texttt{torch.log10(x[:, 0])} and \texttt{torch.log10(x[:, 2])}, respectively. Following the log transformation, the log-transformed mass, log-transformed $V_{max}$, and scale factor node features were normalized to a range between 0 and 1. This normalization was performed to ensure that all features contribute equally to the GNN model's learning process. The minimum and maximum values for each feature were computed across the entire dataset, and then each value was scaled using the formula: \texttt{(value - min) / (max - min)}. The minimum and maximum values for each feature were stored for potential future use or analysis.

\subsubsection{Edge Feature Engineering}
The edge features considered in this study are: mass ratio of merging halos and time difference between mergers. The mass ratio was calculated for each edge as the ratio of the child halo mass to the parent halo mass. Since the parent/child information was not directly available, the halo with the larger mass was assumed to be the parent halo. The time difference was computed as the difference between the scale factors of the merging halos connected by the edge. Subsequently, the edge features were normalized to a range between 0 and 1 using the same min-max scaling procedure applied to the node features. The minimum and maximum values used for normalization were also stored.

\subsubsection{Assembly Bias Proxy Calculation}
An assembly bias proxy was computed for each merger tree. The \texttt{node\_halo\_id} was used to identify halos that exist at $z=0$ (corresponding to a scale factor of 1). For each tree, the indices of the nodes with a scale factor closest to 1 were determined. Note that there can be multiple nodes with a scale factor close to 1. The assembly bias proxy was then calculated as the mean halo mass of the main halos at $z=0$. Due to issues arising during this calculation, the dataset size was drastically reduced.

\subsubsection{Data Splitting}
The dataset was divided into training, validation, and test sets with a ratio of 70:15:15. This split was performed randomly to ensure that each subset is representative of the overall dataset. The training set was used to train the GNN model, the validation set was used for hyperparameter tuning and model selection, and the test set was used to evaluate the final performance of the trained model.

\subsection{Topological Data Analysis (TDA)}

Although the original intention was to use Topological Data Analysis (TDA) to guide the GNN architecture and training, the drastic reduction in dataset size precluded its application. However, the methodology planned for TDA is described below for completeness and potential future use with a larger dataset.

\subsubsection{Filtration}
Each merger tree was to be converted into a simplicial complex. The scale factor was to be used as the filtration parameter, meaning that nodes would be added to the complex in order of increasing scale factor. Edges would be added when both nodes connected by the edge are present in the complex.

\subsubsection{Persistent Homology}
The persistent homology of the simplicial complex was to be computed using a library like \texttt{GUDHI} or \texttt{ripser.py}. Persistence diagrams for H0 (connected components) and H1 (loops) were to be calculated.

\subsubsection{Feature Extraction from Persistence Diagrams}
The following topological features were to be extracted from the persistence diagrams:
\begin{itemize}
    \item Number of connected components at the beginning of the filtration.
    \item Number of loops at different scale factor thresholds (e.g., 0.25, 0.5, 0.75, 1.0).
    \item Average persistence of H0 features (death - birth).
    \item Maximum persistence of H0 features.
    \item Average persistence of H1 features (death - birth).
    \item Maximum persistence of H1 features.
    \item Betti numbers: $\beta_0$ (number of connected components) and $\beta_1$ (number of loops) at different scale factor thresholds (e.g., 0.25, 0.5, 0.75, 1.0).
\end{itemize}

\subsubsection{Correlation Analysis}
The Pearson correlation coefficient was to be calculated between the topological features and the assembly bias proxy on the training set. This would help identify the topological features that are most strongly correlated with assembly bias.

\subsection{Graph Neural Network (GNN) Model}

A Graph Convolutional Network (GCN) architecture was used for the GNN model. The GNN consists of multiple GCN layers, followed by a readout layer and a linear regression layer.

\subsubsection{GNN Architecture}
Each GCN layer performs message passing and node feature aggregation. The number of GCN layers was a hyperparameter to be tuned. The hidden dimension of each GCN layer was also a hyperparameter. After the GCN layers, a readout layer aggregates the node embeddings into a single graph-level embedding. A global mean pooling readout layer was employed. The graph-level embedding is then passed through a linear regression layer to predict the assembly bias proxy. The output is a single scalar value.

\subsubsection{GNN Implementation}
The GNN model was implemented using PyTorch Geometric. The \texttt{torch\_geometric.nn.GCNConv} module was used for the GCN layers.

\subsubsection{Loss Function and Optimizer}
The Mean Squared Error (MSE) loss function was used to train the GNN. The Adam optimizer was used to update the GNN weights. The learning rate and weight decay were hyperparameters to be tuned.

\subsection{Training and Evaluation}

\subsubsection{Hyperparameter Tuning}
Hyperparameter tuning was performed using the validation set. The hyperparameters to be tuned included the number of GCN layers, hidden dimension of GCN layers, learning rate, weight decay, batch size, and number of epochs. A grid search or random search could have been used to explore the hyperparameter space, but given the small dataset size, a limited manual tuning was performed.

\subsubsection{Training Loop}
The GNN model was trained on the training set for a fixed number of epochs. In each epoch, the training data was iterated over in batches. For each batch, the loss was computed, the gradients were calculated, and the GNN weights were updated using the Adam optimizer.

\subsubsection{Validation and Testing}
After each epoch, the GNN model was evaluated on the validation set. The MSE loss and the R-squared score were computed. The validation set was used to select the best GNN model based on the validation loss. After training, the best GNN model was evaluated on the test set. The MSE loss and the R-squared score were computed to estimate the GNN model's generalization performance.

\end{document}
                